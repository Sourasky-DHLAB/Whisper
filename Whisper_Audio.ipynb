
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Mb5sVUCIZDjhaPqSpquodoR8qTcdoRkT",
      "authorship_tag": "ABX9TyOqo/8QZ2/pYv8otSGmizWi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sourasky-DHLAB/Whisper/blob/main/Whisper_Audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=15xQaGVrJej6UIPjfAB-QVWXLWVChPJSt)<br>\n",
        "נכתב על ידי [עודד זרחיה](mailto:odedzarchia@tauex.tau.ac.il) | [Github](https://github.com/Sourasky-DHLAB)<br>\n",
        "[הספרייה המרכזית ע\"ש סוראסקי](https://cenlib.tau.ac.il/) | [אוניברסיטת תל אביב](https://tau.ac.il/)"
      ],
      "metadata": {
        "id": "D8glStTLseMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<div style=\"direction:rtl\" dir=\"rtl\">1. תמלול קבצי אודיו באמצעות Whisper </div>**\n",
        "<div style=\"direction:rtl\" dir=\"rtl\"><p style=\\\"text-align: right; direction: rtl; float: right;\\\">\n",
        "\n",
        "[Whisper](https://openai.com/blog/whisper/) הוא מודל לזיהוי דיבור מבית [OpenAI](https://https://openai.com/) הזמין לציבור הרחב בקוד פתוח. מודל זה אומן על יותר מ-680 אלף שעות של שיחות באנגלית ובשפות רבות אחרות – בהן גם עברית וערבית.\n",
        "\n",
        "מחברת זו תדריך אתכם בתמלול קטעי אודיו באמצעות Whisper. תוכלו להשתמש במחברת כפי שהיא כדי לאחסן את קבצי התמליל ב-Google Drive.\n",
        "\n",
        "לתשומת לבכם - השימוש במחברת זו ובמודל של Whisper חופשי לחלוטין וללא שום עלות. בנוסף, אין הגבלה על אורך קטעי הוידאו/אודיו שניתן לתמלל באמצעות Whisper."
      ],
      "metadata": {
        "id": "0G0FE9s4skOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<div style=\"direction:rtl\" dir=\"rtl\">2. בדוק את סוג המעבד הגרפי (GPU) </div>**\n",
        "<div style=\"direction:rtl\" dir=\"rtl\"><p style=\\\"text-align: right; direction: rtl; float: right;\\\">\n",
        "\n",
        "סוג [המעבד הגרפי](https://https://he.wikipedia.org/wiki/%D7%9E%D7%A2%D7%91%D7%93_%D7%92%D7%A8%D7%A4%D7%99) **(GPU - Graphics Processing Unit)** שאתם מקבלים ב-Google Colab מגדיר את המהירות שבה קטעי האודיו יתומללו. ככל שמספר [הפלופס](https://https://he.wikipedia.org/wiki/FLOPS) **(FLOPS - Floating Point Operations Per Second, פעולות נקודות צפות לשנייה)** גבוה יותר, כך התמלול מהיר יותר. יחד עם זאת, גם המעבד הגרפי החלש ביותר ב-Colab מסוגל להריץ כל מודל של Whisper. יש לוודא כי בחרתם ב-GPU כמאיץ חומרה עבור מחברת זו (Runtime → Change runtime type → Hardware accelerator).\n",
        "</div>\n",
        "\n",
        "|  GPU   |  GPU RAM   | FP32 teraFLOPS |     Availability   |\n",
        "|:------:|:----------:|:--------------:|:------------------:|\n",
        "|  T4    |    16 GB   |       8.1      |         Free       |\n",
        "| P100   |    16 GB   |      10.6      |      Colab Pro     |\n",
        "| V100   |    16 GB   |      15.7      |  Colab Pro (Rare)  |"
      ],
      "metadata": {
        "id": "fsyokosnuUdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "הריצו את התא הבא כדי לוודא את סוג המעבד הגרפי שהוקצה עבור מחברת זו. אפסו את ה-runtime של המחברת אם ברצונכם לקבל מעבד גרפי אחר (Runtime → Restart runtime)."
      ],
      "metadata": {
        "id": "KP_OQ7CiuYx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check gpu type\n",
        "!nvidia-smi -L\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "Rr1Qg5MwuYEG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a83fd03-e33f-4102-f009-e533a9861826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-190c3f16-5016-10dd-4eaa-f47272e521b2)\n",
            "Wed Feb 22 07:31:58 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P0    30W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<div style=\"direction:rtl\" dir=\"rtl\">3. התקנת ספריות </div>**\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "הריצו את התא הבא כדי להוריד ולהתקין את ספריית  [Whisper](https://https://github.com/openai/whisper) הנחוצה לפעולת התמלול."
      ],
      "metadata": {
        "id": "xRAo5l6xufyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install libraries\n",
        "!pip install git+https://github.com/openai/whisper.git "
      ],
      "metadata": {
        "id": "vf4cqkCaZn0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "964d84a4-fdbd-402e-d60f-79aa344e2ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-we56z058\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-we56z058\n",
            "  Resolved https://github.com/openai/whisper.git to commit 7858aa9c08d98f75575035ecd6481f462d66ca27\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.19.0 in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (4.26.1)\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230124) (0.16.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->openai-whisper==20230124) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<div style=\"direction:rtl\" dir=\"rtl\">4. ייבוא ספריות </div>**\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "הריצו את התא הבא כדי לייבא את הספריות הנדרשות עבור פעולת התמלול."
      ],
      "metadata": {
        "id": "rXHJxr7ru7Xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import os"
      ],
      "metadata": {
        "id": "rC-mpBTgZr3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<div style=\"direction:rtl\" dir=\"rtl\">5. חיבור ל-Google Drive </div>**\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "הריצו את התא הבא כדי להתחבר ל-Google Drive האישי שלכם. כדי לראות את הקבצים שלכם פתחו את סייר הקבצים בתפריט השמאלי."
      ],
      "metadata": {
        "id": "R4K42pokvEGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all the audio file paths in a Google Drive folder\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True) # This will prompt for authorization."
      ],
      "metadata": {
        "id": "9LpaqE6ePPIK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2db90f03-cc41-4670-84ff-fb637da90350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<div style=\"direction:rtl\" dir=\"rtl\">6. הגדרת תיקיות </div>**\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "הריצו את התא הבא כדי להגדיר את מיקום קבצי האודיו והתמליל:\n",
        "1. קבצי אודיו - מחברת זו מניחה כי קבצי האודיו לתמלול נמצאים ב-Google Drive תחת תיקיית `Whisper/Audio`. ניתן לשנות הגדרה זו במשתנה `audio_folder`.\n",
        "2. קבצי תמליל - מחברת זו מניחה כי קבצי הטקסט של התמלול יישמרו ב-Google Drive תחת תיקיית `Whisper/Transcriptions`. ניתן לשנות הגדרה זו במשתנה `transcription_folder`. במידה ואינה קיימת, תיקייה זו תיווצר באופן אוטומטי לאחר הרצת התא.\n",
        "\n"
      ],
      "metadata": {
        "id": "yDtp_AGUvPiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the audio files are in a folder called \"Audio\" under \"Whisper\"\n",
        "audio_folder = \"/content/drive/MyDrive/Whisper/Audio/\"\n",
        "\n",
        "# Assuming the text files will be placed in a folder called \"Transcriptions\" under \"Whisper\"\n",
        "transcription_folder = \"/content/drive/MyDrive/Whisper/Transcriptions/\"\n",
        "\n",
        "# Create \"Transcriptions\" folder if does not exist\n",
        "if not os.path.exists(transcription_folder):\n",
        "  os.makedirs(transcription_folder)"
      ],
      "metadata": {
        "id": "e_fKqCK9OQLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<div style=\"direction:rtl\" dir=\"rtl\">7. טעינת קבצי אודיו לתמלול </div>**\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "הריצו את התא הבא כדי לטעון את קבצי האודיו הנמצאים בתיקיית `Whisper/Audio` לתוך משתנה מסוג [רשימה](https://he.wikipedia.org/wiki/%D7%A8%D7%A9%D7%99%D7%9E%D7%94_(%D7%9E%D7%91%D7%A0%D7%94_%D7%A0%D7%AA%D7%95%D7%A0%D7%99%D7%9D) (list). הפלט יצביע על שמות וכמות הקבצים לתמלול."
      ],
      "metadata": {
        "id": "PyZ4xlequt4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all the file paths in the folder\n",
        "audio_files = []\n",
        "for file in os.listdir(audio_folder):\n",
        "    audio_files.append(audio_folder + file)\n",
        "for p in audio_files:\n",
        "    print(p)\n",
        "print(f\"\\033[1m There are {len(audio_files)} audio files to transcribe\")"
      ],
      "metadata": {
        "id": "Lr0_KI8N0mWY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee2dca71-8f2c-4ebd-ac2b-26b02a054fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Whisper/Audio/noga.m4a\n",
            "\u001b[1m There are 1 audio files to transcribe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<div style=\"direction:rtl\" dir=\"rtl\">8. טעינת מודל התמלול </div>**\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "הריצו את התא הבא כדי לטעון את מודל התמלול המתאים.\n",
        "יושם לב כי אנו משתמשים במודל הבינוני (**medium**), וזאת משום שפעולת התמלול צורכת משאבי מחשוב רבים ועלולה לְהַקְרִיס את המחברת. <br>\n",
        "ישנם חמישה מודלים, ארבעה עם גרסאות באנגלית בלבד, המציעים פשרות שונות בין מהירות לדיוק. בטבלה להלן מוצגים שמות המודלים הזמינים יחד עם דרישות הזיכרון והמהירות היחסית שלהם:\n",
        "</div>\n",
        "\n",
        "|  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
        "|:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
        "|  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\n",
        "|  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\n",
        "| small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\n",
        "| medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\n",
        "| large  |   2870 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |\n",
        "\n",
        "<div style=\"direction:rtl\" dir=\"rtl\"><br>\n",
        "\n",
        "במידה וברצונכם להתשמש במודל המדויק ביותר לעברית (**large**) עבור קבצים מרובים, מומלץ להריץ את המחברת בסביבה עם משאבי מחשוב מובטחים כדוגמת Google Colab Pro. עבור תמלול באנגלית בלבד, מודלי ה-en. נוטים לתפקד טוב יותר."
      ],
      "metadata": {
        "id": "FDOniT4Y61aH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load whisper model\n",
        "model = whisper.load_model(\"medium\")\n",
        "print(f\"\\033[1m Model loaded successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToWWQiTv7foY",
        "outputId": "73a8a45b-aec9-4ad8-b682-453e544e3c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m Model loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<div style=\"direction:rtl\" dir=\"rtl\">9. קביעת שפה לתמלול </div>**\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "הריצו את התא הבא כדי להגדיר את שפת התמלול כעברית. כדי להחליף את השפה שנו את ערך המשתנה `lang`.\n",
        "<br>\n",
        "ניתן להדפיס את רשימת השפות הנתמכת על ידי הרצת הפקודה`print(whisper.tokenizer.LANGUAGES)`בתא נפרד. \n"
      ],
      "metadata": {
        "id": "-D_Xnwk0_ZIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lang = 'he'"
      ],
      "metadata": {
        "id": "ZG7xbllv_xvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<div style=\"direction:rtl\" dir=\"rtl\">10. תמלול </div>**\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "הריצו את התא הבא כדי לתמלל את קבצי האודיו בתיקיית `Whisper/Audio`. \n",
        "קבצי הטקסט יישמרו בתיקיית `Whisper/Transcriptions` עם שם זהה לקבצי האודיו אך עם סיומת txt. "
      ],
      "metadata": {
        "id": "Elbd5zmB-_1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set timer\n",
        "import time\n",
        "start_time = time.time()\n",
        "# transcribe audio files in list\n",
        "for p in audio_files:    \n",
        "  result = model.transcribe(p, verbose = False, language = lang)\n",
        "  # name the transcription files \n",
        "  file_name = os.path.basename(p)\n",
        "  text_file = file_name.split(\".\")[0] + \".txt\"\n",
        "  text_file_path = os.path.join(transcription_folder, text_file)\n",
        "  # save transcriptions as text files \n",
        "  with open(text_file_path, 'w') as f:\n",
        "    f.write(result[\"text\"])\n",
        "    print(text_file_path)\n",
        "print(f\"\\033[1m--- Transcribed {len(audio_files)} audio files in  %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "id": "adgPhhduOSyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01567355-f272-4391-83b0-65b5cae76667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261824/261824 [16:24<00:00, 265.86frames/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Whisper/Transcriptions/noga.txt\n",
            "\u001b[1m--- Transcribed 1 audio files in  993.1807384490967 seconds ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}
