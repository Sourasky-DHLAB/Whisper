{"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"https://github.com/Sourasky-DHLAB/Whisper/blob/main/Whisper_Audio.ipynb","authorship_tag":"ABX9TyOJWZHFyIp/xy4IRA6S6r5g","include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"gpuClass":"premium","accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://kaggle.com/kernels/welcome?src=https://github.com/Sourasky-DHLAB/Whisper/blob/main/kaggle-whisper-audio.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"markdown","source":"<div style=\"direction:rtl\" dir=\"rtl\">\n    <img src=\"https://drive.google.com/uc?export=view&amp;id=15xQaGVrJej6UIPjfAB-QVWXLWVChPJSt\"><br>\n<div style=\"direction:rtl\" dir=\"rtl\">\n  <p style=\"text-align: right; direction: rtl; float: right;\">    נכתב על ידי <a href=\"mailto:odedzarchia@tauex.tau.ac.il\">עודד זרחיה</a> | <a href=\"https://github.com/Sourasky-DHLAB\">Github</a><br>\n    <a href=\"https://cenlib.tau.ac.il/\">הספרייה המרכזית ע\"ש סוראסקי</a> | <a href=\"https://tau.ac.il/\">אוניברסיטת תל אביב</a>\n</div></p>","metadata":{"id":"D8glStTLseMc"}},{"cell_type":"markdown","source":"<div dir=\"rtl\">\n<h1><strong>1. תמלול קבצי אודיו באמצעות Whisper</strong></h1>\n<p>\n<div style=\"direction:rtl\" dir=\"rtl\">\n  <p style=\"text-align: right; direction: rtl; float: right;\">\n<a href=\"https://openai.com/blog/whisper/\"> Whisper </a>הוא מודל לזיהוי דיבור מבית <a href=\"https://openai.com/\">OpenAI</a> הזמין לציבור הרחב בקוד פתוח. מודל זה אומן על יותר מ-680 אלף שעות של שיחות באנגלית ובשפות רבות אחרות – בהן גם עברית וערבית.<br>\nמחברת זו תדריך אתכם בתמלול קטעי אודיו באמצעות Whisper. תוכלו להשתמש במחברת כפי שהיא כדי להוריד את קבצי התמליל מ-Kaggle.<br>\nלתשומת לבכם - השימוש במחברת זו ובמודל של Whisper חופשי לחלוטין וללא שום עלות. בנוסף, אין הגבלה על אורך קטעי הוידאו/אודיו שניתן לתמלל באמצעות Whisper.\n</p>\n</div>","metadata":{"id":"0G0FE9s4skOt"}},{"cell_type":"markdown","source":"<h1><strong><div style=\"direction:rtl\" dir=\"rtl\">2. בדוק את סוג המעבד הגרפי (GPU) </div></strong></h1>\n<div style=\"direction:rtl\" dir=\"rtl\">\n  <p style=\"text-align: right; direction: rtl; float: right;\">סוג <a href=\"https://https://he.wikipedia.org/wiki/%D7%9E%D7%A2%D7%91%D7%93_%D7%92%D7%A8%D7%A4%D7%99\">המעבד הגרפי</a> <strong>(GPU - Graphics Processing Unit)</strong> שאתם מקבלים ב-Kaggle מגדיר את המהירות שבה קטעי האודיו יתומללו. ככל שמספר <a href=\"https://https://he.wikipedia.org/wiki/FLOPS\">הפלופס</a> <strong>(FLOPS - Floating Point Operations Per Second, פעולות נקודות צפות לשנייה)</strong> גבוה יותר, כך התמלול מהיר יותר. יחד עם זאת, גם המעבד הגרפי החלש ביותר ב-Kaggle מסוגל להריץ כל מודל של Whisper. יש לוודא כי בחרתם ב-GPU כמאיץ חומרה עבור מחברת זו (Notebook options → ACCELERATOR → GPU T4 *2/GPU P100).</p>\n</div>\n\n<table>\n  <thead>\n    <tr>\n      <th>GPU</th>\n      <th>GPU RAM</th>\n      <th>FP32 teraFLOPS</th>\n      <th>Availability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>T4</td>\n      <td>16 GB</td>\n      <td>8.1</td>\n      <td>Free</td>\n    </tr>\n    <tr>\n      <td>P100</td>\n      <td>16 GB</td>\n      <td>10.6</td>\n      <td>Colab Pro</td>\n    </tr>\n    <tr>\n      <td>V100</td>\n      <td>16 GB</td>\n      <td>15.7</td>\n      <td>Colab Pro (Rare)</td>\n    </tr>\n  </tbody>\n</table>","metadata":{"id":"fsyokosnuUdk"}},{"cell_type":"code","source":"# check gpu type\n!nvidia-smi -L\n!nvidia-smi","metadata":{"id":"Rr1Qg5MwuYEG","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"direction:rtl\" dir=\"rtl\"><h1><strong>3. התקנת ספריות</strong></h1>\n<div style=\"direction:rtl\" dir=\"rtl\">\n  <p style=\"text-align: right; direction: rtl; float: right;\">הריצו את התא הבא כדי להוריד ולהתקין את ספריית <a href=\"https://github.com/openai/whisper\">Whisper</a> הנחוצה לפעולת התמלול.</p></div>","metadata":{"id":"xRAo5l6xufyF"}},{"cell_type":"code","source":"# install libraries\n!pip install -U openai-whisper\n!pip install jiwer","metadata":{"id":"vf4cqkCaZn0U","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"direction:rtl\" dir=\"rtl\">\n  <h1><strong>4. ייבוא ספריות </strong></h1>\n  <div style=\"direction:rtl\" dir=\"rtl\">\n  <p style=\"text-align: right; direction: rtl; float: right;\">הריצו את התא הבא כדי לייבא את הספריות הנדרשות עבור פעולת התמלול.</p>\n</div>","metadata":{"id":"rXHJxr7ru7Xr"}},{"cell_type":"code","source":"# import libraries\nimport whisper\nfrom whisper.utils import get_writer\nimport os\nimport string\nfrom jiwer import wer","metadata":{"id":"rC-mpBTgZr3D","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 dir=\"rtl\"><strong>6. הגדרת תיקיות </strong></h1>\n<div dir=\"rtl\" style=\"direction: rtl;\">\n<p style=\"text-align: right; direction: rtl; float: right;\">הריצו את התא הבא כדי להגדיר את מיקום קבצי האודיו והתמליל:</p>\n<ol style=\"float: right;\">\n<li>קבצי אודיו - מחברת זו מניחה כי קבצי האודיו לתמלול נמצאים ב-Kaggle תחת תיקיית <code>kaggle/input/audiofiles/</code>. כדי ליצור תיקייה זו יש ללחוץ על upload data ולהעלות את קבצי האודיו שלכם אל dataset חדש בשם <code>audiofiles</code>.</li>\n<li>קבצי תמליל - מחברת זו מניחה כי קבצי הטקסט של התמלול יישמרו ב-Kaggle תחת תיקיית <code>kaggle/working/</code>. תיקייה זו נוצרת באופן אוטומטי.</li>\n</ol>\n</div>","metadata":{"id":"yDtp_AGUvPiS"}},{"cell_type":"code","source":"# Assuming the audio files are in a folder called \"Audio\" under \"Whisper\"\naudio_folder = \"/kaggle/input/audiofiles/\"\n\n# Assuming the text files will be placed in a folder called \"Transcriptions\" under \"Whisper\"\ntranscription_folder = \"/kaggle/working/\"","metadata":{"id":"e_fKqCK9OQLE","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1><strong><div style=\"direction:rtl\" dir=\"rtl\">7. טעינת קבצי אודיו לתמלול </div></h1></strong>\n<div style=\"direction:rtl\" dir=\"rtl\">\n  <p style=\"text-align: right; direction: rtl; float: right;\">\nהריצו את התא הבא כדי לטעון את קבצי האודיו הנמצאים בתיקיית <code>kaggle/input/audiofiles/</code> לתוך משתנה מסוג <a href=\"https://he.wikipedia.org/wiki/%D7%A8%D7%A9%D7%99%D7%9E%D7%94_(%D7%9E%D7%91%D7%A0%D7%94_%D7%A0%D7%AA%D7%95%D7%A0%D7%99%D7%9D)\">רשימה</a> (list). הפלט יציג את שמות וכמות הקבצים לתמלול.</p>","metadata":{"id":"PyZ4xlequt4r"}},{"cell_type":"code","source":"# Get a list of all the file paths in the folder\naudio_files = []\nfor file in os.listdir(audio_folder):\n    audio_files.append(audio_folder + file)\nfor p in audio_files:\n    print(p)\nprint(f\"\\033[1m There are {len(audio_files)} audio files to transcribe\")","metadata":{"id":"Lr0_KI8N0mWY","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 id=\"-div-style-direction-rtl-dir-rtl-8-div-\"><strong><div style=\"direction:rtl\" dir=\"rtl\">8. טעינת מודל התמלול </div></strong></h1>\n<div style=\"direction:rtl\" dir=\"rtl\">\n  <p style=\"text-align: right; direction: rtl; float: right;\">הריצו את התא הבא כדי לטעון את מודל התמלול המתאים. יושם לב כי אנו משתמשים במודל הגדול (<strong>large</strong>), המדויק ביותר עבור השפה העברית. <br> ישנם חמישה מודלים, ארבעה עם גרסאות באנגלית בלבד, המציעים פשרות שונות בין מהירות לדיוק. יושם לב כי פעולת התמלול צורכת משאבי מחשוב מרובים. לפיכך, אם ברצונכם להשתמש במודל הגדול עבור קבצים מרובים, מומלץ להריץ את המחברת בסביבה עם משאבי מחשוב מובטחים כדוגמת <a href=\"https://colab.research.google.com/signup\">Google Colab Pro</a>. עבור תמלול באנגלית בלבד, מודלי ה-en. נוטים לתפקד טוב יותר. <br>בטבלה שלהלן מוצגים שמות המודלים הזמינים יחד עם דרישות הזיכרון והמהירות היחסית שלהם:\n</div>\n\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Size</th>\n<th style=\"text-align:center\">Parameters</th>\n<th style=\"text-align:center\">English-only model</th>\n<th style=\"text-align:center\">Multilingual model</th>\n<th style=\"text-align:center\">Required VRAM</th>\n<th style=\"text-align:center\">Relative speed</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">tiny</td>\n<td style=\"text-align:center\">39 M</td>\n<td style=\"text-align:center\"><code>tiny.en</code></td>\n<td style=\"text-align:center\"><code>tiny</code></td>\n<td style=\"text-align:center\">~1 GB</td>\n<td style=\"text-align:center\">~32x</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">base</td>\n<td style=\"text-align:center\">74 M</td>\n<td style=\"text-align:center\"><code>base.en</code></td>\n<td style=\"text-align:center\"><code>base</code></td>\n<td style=\"text-align:center\">~1 GB</td>\n<td style=\"text-align:center\">~16x</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">small</td>\n<td style=\"text-align:center\">244 M</td>\n<td style=\"text-align:center\"><code>small.en</code></td>\n<td style=\"text-align:center\"><code>small</code></td>\n<td style=\"text-align:center\">~2 GB</td>\n<td style=\"text-align:center\">~6x</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">medium</td>\n<td style=\"text-align:center\">769 M</td>\n<td style=\"text-align:center\"><code>medium.en</code></td>\n<td style=\"text-align:center\"><code>medium</code></td>\n<td style=\"text-align:center\">~5 GB</td>\n<td style=\"text-align:center\">~2x</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">large</td>\n<td style=\"text-align:center\">2870 M</td>\n<td style=\"text-align:center\">N/A</td>\n<td style=\"text-align:center\"><code>large</code></td>\n<td style=\"text-align:center\">~10 GB</td>\n<td style=\"text-align:center\">1x</td>\n</tr>\n</tbody>\n</table>\n<p><div style=\"direction:rtl\" dir=\"rtl\"><br></p>","metadata":{"id":"FDOniT4Y61aH"}},{"cell_type":"code","source":"# load whisper model\nmodel = whisper.load_model(\"medium\")\nprint(f\"\\033[1m Model loaded successfully\")","metadata":{"id":"ToWWQiTv7foY","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 id=\"-div-style-direction-rtl-dir-rtl-9-div-\"><strong><div style=\"direction:rtl\" dir=\"rtl\">9. קביעת שפה לתמלול וסוג הפלט</div></strong></h1>\n<div style=\"direction:rtl\" dir=\"rtl\">\n <p style=\"text-align: right; direction: rtl; float: right;\">הריצו את התא הבא כדי לקבוע שני משתנים:\n<ol style=\"float:right;\">\n  <li><code>lang</code> - הגדרת שפת התמלול. <code>he</code> משמעו עברית. ניתן להדפיס את רשימת השפות הנתמכת על ידי הרצת הפקודה <code>print(whisper.tokenizer.LANGUAGES)</code> בתא נפרד.</li>\n  <li><code>output_format</code> - הגדרת סוג הפלט. Whisper תומך בהפקת הפלטים הבאים:\n    <ul>\n      <li><code>txt</code> - קובץ טקסט עם מעברי שורות, ניתן לפתיחה בכל מעבד תמלילים.</li>\n      <li><code>srt/vtt</code>- קבצי כתוביות המכילים טקסט וחתימות זמן.</li>\n      <li><code>tsv</code>- קובץ טקסט מופרד בטאבים עם חלוקה לסגמנטים. ניתן לפתיחה כגיליון אלקטרוני.</li>\n      <li><code>json</code>- מבנה מידע המורכב מזוגות של מפתח-ערך.</li>\n    </ul><br>\n    החליפו את ערך המשתנה בהתאם לסוג הפלט שברצונכם לקבל. ניתן להפיק את כל סוגי הפלטים באמצעות קביעת הערך <code>all</code>.</p>\n  </li>\n</ol>\n</div>","metadata":{"id":"-D_Xnwk0_ZIG"}},{"cell_type":"code","source":"lang = 'he'\noutput_format = 'txt'","metadata":{"id":"ZG7xbllv_xvO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 id=\"-div-style-direction-rtl-dir-rtl-10-div-\"><strong><div style=\"direction:rtl\" dir=\"rtl\">10. תמלול </div></strong></h1>\n<div style=\"direction:rtl\" dir=\"rtl\">\n  <p style=\"text-align: right; direction: rtl; float: right;\">\nהריצו את התא הבא כדי לתמלל את קבצי האודיו בתיקיית <code>Whisper/Audio</code>. \nקבצי הטקסט יישמרו בתיקיית <code>Whisper/Transcriptions</code> עם שם זהה לקבצי האודיו אך עם סיומת txt. </p>","metadata":{"id":"Elbd5zmB-_1a"}},{"cell_type":"code","source":"# set timer\nimport time\nstart_time = time.time()\n# transcribe audio files in list\nfor p in audio_files:    \n  result = model.transcribe(p, verbose = False, language = lang) # to translate add task = 'transalte'\n  # use get_writer method to output files\n  output_file = get_writer(output_format, transcription_folder)\n  output_file(result, p[:-4])\n  print(p)\nprint(f\"\\033[1m--- Transcribed {len(audio_files)} audio files in %s seconds ---\" % (time.time() - start_time))","metadata":{"id":"adgPhhduOSyz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 id=\"-div-style-direction-rtl-dir-rtl-11-div-\"><strong><div style=\"direction:rtl\" dir=\"rtl\">11. בדיקת איכות (אופציונלי) </div></strong></h1>\n<div style=\"direction:rtl\" dir=\"rtl\">\n\n<p style=\"text-align: right; direction: rtl; float: right;\">הרצת התאים הבאים תאפשר לכם להעריך את הדיוק של התמלול שהפקתם באמצעות Whisper. בדיקה זו מתבצעת במספר שלבים, ומצריכה את קובץ התמלול המקורי (<a href=\"https://https://en.wikipedia.org/wiki/Ground_truth\">Ground Truth</a>): </p>\n<ol style=\"float:right;\">\n<li>נירמול פלט התמלול של Whisper וקובץ התמלול המקורי  - הסרת סימני פיסוק, רווחים מיותרים, קפיטליזציה וכו&#39;. הנתיב של הקובץ שהפקתם באמצעות Whisper מוגדר במשתנה מוגדר במשתנה <code>whisper_output</code>. הנתיב של קובץ התמלול המקורי מוגדר במשתנה <code>ground_truth</code>.</li>\n<li>השוואה בין שני הקבצים וחישוב אחוז השגיאות בהתאם למדד <a href=\"https://https://en.wikipedia.org/wiki/Word_error_rate\">Word Error Rate</a> - באמצעות ספריית jiwer.</li>\n</ol>\n<p style=\"text-align: right; direction: rtl; float: right;\">הפלט המתקבל מוצג באחוזים ומצביע על אחוז המילים השגויות בקובץ התמלול, וזאת בהשוואה לקובץ המקור. כלומר, במידה ואחוז השגיאות עומד על כ-3%, אזי מתוך 100 מילים יש 3 מילים שגויות.</p>","metadata":{"id":"8gNRHYaXRutE"}},{"cell_type":"code","source":"# normalize whisper output\nwhisper_output = '/kaggle/working/Hayut.txt'\nwhisper_output_norm = open(whisper_output, 'r').read().lower().translate(str.maketrans('', '', string.punctuation)).replace('\\n', ' ')\nprint(whisper_output_norm)","metadata":{"id":"sL1NPgEhSONs","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalize ground truth\nground_truth = '/kaggle/input/ground-truth/Hayut_GT.txt'\nground_truth_norm = open(ground_truth, 'r').read().lower().translate(str.maketrans('', '', string.punctuation)).replace('\\n', ' ')\nprint(ground_truth_norm)","metadata":{"id":"zTOY_r7kUsBc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate WER\nreference = ground_truth_norm\nhypothesis = whisper_output_norm\nerror = wer(reference, hypothesis)\nerror_percentage = \"{:.0%}\".format(error)\nprint(error_percentage)","metadata":{"id":"w6mR6ErlVUwD","trusted":true},"execution_count":null,"outputs":[]}]}