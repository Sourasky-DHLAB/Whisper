{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sourasky-DHLAB/Whisper/blob/main/Colab/Whisper_Speaker_Diarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8glStTLseMc"
      },
      "source": [
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "    <img src=\"http://drive.google.com/uc?export=view&id=1FnLVIqEV1Tt5rCEOIk5OxihO6xdZgTMe\"><br>\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "  <p style=\"text-align: right; direction: rtl; float: right;\">    נכתב על ידי <a href=\"mailto:odedzarchia@tauex.tau.ac.il\">עודד זרחיה</a> | <a href=\"https://github.com/Sourasky-DHLAB\">Github</a><br>\n",
        "    <a href=\"https://cenlib.tau.ac.il/\">הספרייה המרכזית ע\"ש סוראסקי</a> | <a href=\"https://tau.ac.il/\">אוניברסיטת תל אביב</a>\n",
        "</div></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G0FE9s4skOt"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "<h1><strong>1. תמלול אודיו וזיהוי דוברים עם Whisper ו-pyannote.audio</strong></h1>\n",
        "<p>\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "  <p style=\"text-align: right; direction: rtl; float: right;\">\n",
        "<a href=\"https://openai.com/blog/whisper/\"> Whisper </a>הוא מודל לזיהוי דיבור מבית <a href=\"https://openai.com/\">OpenAI</a> הזמין לציבור הרחב בקוד פתוח. מודל זה אומן על יותר מ-680 אלף שעות של שיחות באנגלית ובשפות רבות אחרות – בהן גם עברית וערבית.<br>\n",
        "<a href = \"https://github.com/pyannote/pyannote-audio\">pyannote.audio</a> היא ספריית כלים בפייתון לזיהוי דוברים המבוססת על למידת מכונה. <br>\n",
        "מחברת זו תדריך אתכם בתמלול ראיונות מוקלטים באמצעות Whisper ו-pyannote.audio. תוכלו להשתמש במחברת כפי שהיא כדי לאחסן את קבצי התמליל ב-Google Drive.<br>\n",
        "לתשומת לבכם - השימוש במחברת זו ובמודלים השונים חופשי לחלוטין וללא שום עלות. בנוסף, אין הגבלה על אורך קטעי הוידאו/אודיו שניתן לתמלל באמצעות Whisper.\n",
        "</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsyokosnuUdk"
      },
      "source": [
        "<h1><strong><div style=\"direction:rtl\" dir=\"rtl\">2. בדוק את סוג המעבד הגרפי (GPU) </div></strong></h1>\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "  <p style=\"text-align: right; direction: rtl; float: right;\">סוג <a href=\"https://https://he.wikipedia.org/wiki/%D7%9E%D7%A2%D7%91%D7%93_%D7%92%D7%A8%D7%A4%D7%99\">המעבד הגרפי</a> <strong>(GPU - Graphics Processing Unit)</strong> שאתם מקבלים ב-Google Colab מגדיר את המהירות שבה קטעי האודיו יתומללו. ככל שמספר <a href=\"https://https://he.wikipedia.org/wiki/FLOPS\">הפלופס</a> <strong>(FLOPS - Floating Point Operations Per Second, פעולות נקודות צפות לשנייה)</strong> גבוה יותר, כך התמלול מהיר יותר. יחד עם זאת, גם המעבד הגרפי החלש ביותר ב-Colab מסוגל להריץ כל מודל של Whisper. יש לוודא כי בחרתם ב-GPU כמאיץ חומרה עבור מחברת זו (Runtime → Change runtime type → Hardware accelerator).</p>\n",
        "</div>\n",
        "\n",
        "<table>\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th>GPU</th>\n",
        "      <th>GPU RAM</th>\n",
        "      <th>FP32 teraFLOPS</th>\n",
        "      <th>Availability</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td>T4</td>\n",
        "      <td>16 GB</td>\n",
        "      <td>8.1</td>\n",
        "      <td>Free</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>P100</td>\n",
        "      <td>16 GB</td>\n",
        "      <td>10.6</td>\n",
        "      <td>Colab Pro</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>V100</td>\n",
        "      <td>16 GB</td>\n",
        "      <td>15.7</td>\n",
        "      <td>Colab Pro (Rare)</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "\n",
        "\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "  <p style=\"text-align: right; direction: rtl; float: right;\">\n",
        "הריצו את התא הבא כדי לוודא את סוג המעבד הגרפי שהוקצה עבור מחברת זו. אפסו את ה-runtime של המחברת אם ברצונכם לקבל מעבד גרפי אחר (Runtime → Restart runtime).</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rr1Qg5MwuYEG"
      },
      "outputs": [],
      "source": [
        "# check gpu type\n",
        "!nvidia-smi -L\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"direction:rtl\" dir=\"rtl\"><h1><strong>3. התקנת ספריות - למידת מכונה</strong></h1>\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "  <p style=\"text-align: right; direction: rtl; float: right;\">הריצו את התא הבא כדי להוריד ולהתקין את ספריות לימוד המכונה הנחוצות לזיהוי הדוברים."
      ],
      "metadata": {
        "id": "7fPQX_LIUMiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.0.0\n",
        "!pip install torch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1 torchtext==0.14.1 fastai==2.7.11\n",
        "!pip install tokenizers\n",
        "!pip install torchdata==0.5.1"
      ],
      "metadata": {
        "id": "Heygar7COSa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRAo5l6xufyF"
      },
      "source": [
        "<div style=\"direction:rtl\" dir=\"rtl\"><h1><strong>4. התקנת ספריות - תמלול וזיהוי דוברים</strong></h1>\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "  <p style=\"text-align: right; direction: rtl; float: right;\">הריצו את התא הבא כדי להוריד ולהתקין את ספריית <a href=\"https://github.com/openai/whisper\">Whisper</a> הנחוצה לפעולת התמלול ואת ספריית <a href = https://github.com/pyannote/pyannote-audio>pyannote.audio</a> לזיהוי דוברים.</p></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vf4cqkCaZn0U"
      },
      "outputs": [],
      "source": [
        "# install libraries\n",
        "!pip install git+https://github.com/openai/whisper.git \n",
        "!pip install -q git+https://github.com/pyannote/pyannote-audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXHJxr7ru7Xr"
      },
      "source": [
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "  <h1><strong>5. ייבוא ספריות </strong></h1>\n",
        "  <div style=\"direction:rtl\" dir=\"rtl\">\n",
        "  <p style=\"text-align: right; direction: rtl; float: right;\">הריצו את התא הבא  כדי לייבא את הספריות הנדרשות עבור פעולות התמלול וזיהוי הדוברים.</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rC-mpBTgZr3D"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import whisper\n",
        "import os\n",
        "from os.path import join\n",
        "import time\n",
        "import datetime\n",
        "import subprocess\n",
        "import torch\n",
        "import pyannote.audio\n",
        "from pyannote.audio.pipelines.speaker_verification import PretrainedSpeakerEmbedding\n",
        "embedding_model = PretrainedSpeakerEmbedding( \n",
        "    \"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "    device=torch.device(\"cuda\"))\n",
        "from pyannote.audio import Audio\n",
        "from pyannote.core import Segment\n",
        "import wave\n",
        "import contextlib\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np\n",
        "from os.path import join"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4K42pokvEGa"
      },
      "source": [
        "<h1><strong><div style=\"direction:rtl\" dir=\"rtl\">6. חיבור ל-Google Drive </div></strong></h1>\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "  <p style=\"text-align: right; direction: rtl; float: right;\">הריצו את התא הבא כדי להתחבר ל-Google Drive האישי שלכם. כדי לראות את הקבצים שלכם פתחו את סייר הקבצים בתפריט השמאלי.</p></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9LpaqE6ePPIK",
        "outputId": "90770880-6091-4598-8e9e-58f2ba5b8aaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True) # This will prompt for authorization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDtp_AGUvPiS"
      },
      "source": [
        "<h1 dir=\"rtl\"><strong>7. הגדרת תיקיות </strong></h1>\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "  <p style=\"text-align: right; direction: rtl; float: right;\">הריצו את התא הבא כדי להגדיר את מיקום קובץ הקלט (אודיו) וקובץ הפלט (טקסט):<br>\n",
        "    <ol style=\"float:right;\">\n",
        "          <li>קובץ אודיו - מיקום קובץ האודיו לתמלול מוגדר תחת משתנה  <code>audio_file</code>.העתיקו את מיקום קובץ האודיו שברצונכם לתמלל והדביקו אותו במשתנה זה. שימרו על המרכאות.<b> יושם לב כי על קובץ הראיון להיות בפורמט<code>WAV</code></b>.<br> במידה והקובץ שברשותכם נמצא בפורמט אחר (אודיו/וידאו), ניתן להמירו באמצעות תוכנות לעריכת וידאו/אודיו המגיעות עם מערכת ההפעלה (Clipchamp, Sound Converter וכולי) או דרך אפליקציות מקוונות ברשת האינטרנט. העתיקו את</li>\n",
        "      <li>קובץ תמליל - מחברת זו מניחה כי קובץ הטקסט של התמלול יישמר ב-Google Drive תחת תיקיית <code>Whisper/Transcriptions/</code>. ניתן לשנות הגדרה זו במשתנה <code>transcription_folder_path</code>. במידה ואינה קיימת, תיקייה זו תיווצר באופן אוטומטי לאחר הרצת התא.</li>\n",
        "    </ol>\n",
        "  </p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "e_fKqCK9OQLE"
      },
      "outputs": [],
      "source": [
        "# Set audio file location\n",
        "audio_file = \"/content/drive/MyDrive/Whisper/Audio/Piers_Morgan_vs_Benjamin_Netanyahu.wav\"\n",
        "\n",
        "# Assuming the text files will be placed in a folder called \"Transcriptions\" under \"Whisper\"\n",
        "transcription_folder_path = \"/content/drive/MyDrive/Whisper/Transcriptions/\"\n",
        "\n",
        "# Create \"Transcriptions\" folder if does not exist\n",
        "if not os.path.exists(transcription_folder_path):\n",
        "  os.makedirs(transcription_folder_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDOniT4Y61aH"
      },
      "source": [
        "<h1 id=\"-div-style-direction-rtl-dir-rtl-8-div-\"><strong><div style=\"direction:rtl\" dir=\"rtl\">8. טעינת מודל התמלול </div></strong></h1>\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "  <p style=\"text-align: right; direction: rtl; float: right;\">הריצו את התא הבא כדי לטעון את מודל התמלול המתאים. יושם לב כי אנו משתמשים במודל הגדול (<strong>large</strong>), המדויק ביותר עבור השפה העברית. <br> ישנם חמישה מודלים, ארבעה עם גרסאות באנגלית בלבד, המציעים פשרות שונות בין מהירות לדיוק. יושם לב כי פעולת התמלול צורכת משאבי מחשוב מרובים. לפיכך, אם ברצונכם להשתמש במודל הגדול עבור קבצים מרובים, מומלץ להריץ את המחברת בסביבה עם משאבי מחשוב מובטחים כדוגמת <a href=\"https://colab.research.google.com/signup\">Google Colab Pro</a>. עבור תמלול באנגלית בלבד, מודלי ה-en. נוטים לתפקד טוב יותר. <br>בטבלה שלהלן מוצגים שמות המודלים הזמינים יחד עם דרישות הזיכרון והמהירות היחסית שלהם:\n",
        "</div>\n",
        "\n",
        "<table>\n",
        "<thead>\n",
        "<tr>\n",
        "<th style=\"text-align:center\">Size</th>\n",
        "<th style=\"text-align:center\">Parameters</th>\n",
        "<th style=\"text-align:center\">English-only model</th>\n",
        "<th style=\"text-align:center\">Multilingual model</th>\n",
        "<th style=\"text-align:center\">Required VRAM</th>\n",
        "<th style=\"text-align:center\">Relative speed</th>\n",
        "</tr>\n",
        "</thead>\n",
        "<tbody>\n",
        "<tr>\n",
        "<td style=\"text-align:center\">tiny</td>\n",
        "<td style=\"text-align:center\">39 M</td>\n",
        "<td style=\"text-align:center\"><code>tiny.en</code></td>\n",
        "<td style=\"text-align:center\"><code>tiny</code></td>\n",
        "<td style=\"text-align:center\">~1 GB</td>\n",
        "<td style=\"text-align:center\">~32x</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td style=\"text-align:center\">base</td>\n",
        "<td style=\"text-align:center\">74 M</td>\n",
        "<td style=\"text-align:center\"><code>base.en</code></td>\n",
        "<td style=\"text-align:center\"><code>base</code></td>\n",
        "<td style=\"text-align:center\">~1 GB</td>\n",
        "<td style=\"text-align:center\">~16x</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td style=\"text-align:center\">small</td>\n",
        "<td style=\"text-align:center\">244 M</td>\n",
        "<td style=\"text-align:center\"><code>small.en</code></td>\n",
        "<td style=\"text-align:center\"><code>small</code></td>\n",
        "<td style=\"text-align:center\">~2 GB</td>\n",
        "<td style=\"text-align:center\">~6x</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td style=\"text-align:center\">medium</td>\n",
        "<td style=\"text-align:center\">769 M</td>\n",
        "<td style=\"text-align:center\"><code>medium.en</code></td>\n",
        "<td style=\"text-align:center\"><code>medium</code></td>\n",
        "<td style=\"text-align:center\">~5 GB</td>\n",
        "<td style=\"text-align:center\">~2x</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td style=\"text-align:center\">large</td>\n",
        "<td style=\"text-align:center\">2870 M</td>\n",
        "<td style=\"text-align:center\">N/A</td>\n",
        "<td style=\"text-align:center\"><code>large</code></td>\n",
        "<td style=\"text-align:center\">~10 GB</td>\n",
        "<td style=\"text-align:center\">1x</td>\n",
        "</tr>\n",
        "</tbody>\n",
        "</table>\n",
        "<p><div style=\"direction:rtl\" dir=\"rtl\"><br></p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToWWQiTv7foY"
      },
      "outputs": [],
      "source": [
        "# load whisper model\n",
        "model = whisper.load_model(\"tiny.en\")\n",
        "print(f\"\\033[1m Model loaded successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D_Xnwk0_ZIG"
      },
      "source": [
        "<h1 id=\"-div-style-direction-rtl-dir-rtl-9-div-\"><strong><div style=\"direction:rtl\" dir=\"rtl\">9. קביעת שפה ומספר דוברים</div></strong></h1>\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        " <p style=\"text-align: right; direction: rtl; float: right;\">הריצו את התא הבא כדי לקבוע שני משתנים:\n",
        "<ol style=\"float:right;\">\n",
        "  <li><code>lang</code> - הגדרת שפת התמלול. <code>he</code> משמעו עברית. ניתן להדפיס את רשימת השפות הנתמכת על ידי הרצת הפקודה <code>print(whisper.tokenizer.LANGUAGES)</code> בתא נפרד.</li>\n",
        "  <li><code>num_speakers</code> - שנו בהתאם למספר הדוברים בקובץ האודיו (לדוגמה, שני מראיינים ומרואיין אחד = 3).</p>\n",
        "  </li>\n",
        "</ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZG7xbllv_xvO"
      },
      "outputs": [],
      "source": [
        "lang = 'en'\n",
        "num_speakers = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Elbd5zmB-_1a"
      },
      "source": [
        "<h1 id=\"-div-style-direction-rtl-dir-rtl-10-div-\"><strong><div style=\"direction:rtl\" dir=\"rtl\">10. תמלול </div></strong></h1>\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "  <p style=\"text-align: right; direction: rtl; float: right;\">\n",
        "הריצו את התא הבא כדי לתמלל את קבצי ה-<code>WAV</code> בתיקיית <code>Whisper/Audio</code>. פלט התמליל, המוגדר תחת משתנה <code>segments</code>, יתקבל בחלוקה לסגמנטים (רצף של קטעי שמע בדידים). </p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adgPhhduOSyz"
      },
      "outputs": [],
      "source": [
        "# set timer\n",
        "import time\n",
        "start_time = time.time()\n",
        "# transcribe interview file\n",
        "result = model.transcribe(audio_file, verbose = False, language = lang) # to translate add task = 'transalte'\n",
        "segments = result[\"segments\"]\n",
        "print(f\"\\033[1m--- Transcribed file in %s seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 id=\"-div-style-direction-rtl-dir-rtl-10-div-\"><strong><div style=\"direction:rtl\" dir=\"rtl\">11. טעינת קובץ WAV </div></strong></h1>\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "  <p style=\"text-align: right; direction: rtl; float: right;\">\n",
        "הריצו את התא הבא כדי לטעון את קובץ ה-<code>WAV</code> ולחלץ את נתוני המטא-דאטה.</p>"
      ],
      "metadata": {
        "id": "tM55isNaH6D1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with contextlib.closing(wave.open(audio_file,'r')) as f:\n",
        "  frames = f.getnframes()\n",
        "  rate = f.getframerate()\n",
        "  duration = frames / float(rate)\n",
        "  \n",
        "print(f\"\\033[1m--- The file contains {frames} audio frames ---\")\n",
        "print(f\"\\033[1m--- The sampling frequency is {rate} Hz ---\")\n",
        "print(f\"\\033[1m--- The duration is {duration} seconds ---\")"
      ],
      "metadata": {
        "id": "1hjOh5Iwi2dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 id=\"-div-style-direction-rtl-dir-rtl-10-div-\"><strong><div style=\"direction:rtl\" dir=\"rtl\">12. חלוקת קובץ ה-WAV למקטעים ויצירת embedding </div></strong></h1>\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "  <p style=\"text-align: right; direction: rtl; float: right;\">\n",
        "הריצו את התא הבא כדי להגדיר פונקציה בשם <code>segment_embedding</code>. פונקציה זו חותכת את קובץ האודיו למקטעים על סמך נתוני הסגמנטציה שהתקבלו במהלך פעולת התמלול. לאחר מכן, הפונקציה יוצרת <a href = \"https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture#:~:text=An%20embedding%20is%20a%20relatively,like%20sparse%20vectors%20representing%20words.\">embedding</a> עבור כל סגמנט אודיו.</p> "
      ],
      "metadata": {
        "id": "D3u2wp0lNhEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio = Audio()\n",
        "\n",
        "def segment_embedding(segment):\n",
        "  start = segment[\"start\"]\n",
        "  # Whisper overshoots the end timestamp in the last segment\n",
        "  end = min(duration, segment[\"end\"])\n",
        "  clip = Segment(start, end)\n",
        "  waveform, sample_rate = audio.crop(audio_file, clip)\n",
        "  return embedding_model(waveform[None])"
      ],
      "metadata": {
        "id": "2EZYUWTPOo1K"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 id=\"-div-style-direction-rtl-dir-rtl-10-div-\"><strong><div style=\"direction:rtl\" dir=\"rtl\">13. יצירת מערך ואחסון ה-embeddings </div></strong></h1>\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "  <p style=\"text-align: right; direction: rtl; float: right;\">\n",
        "הריצו את התא הבא כדי ליצור מערך <a href = \"https://pypi.org/project/numpy/\">numpy</a> בו יאוחסנו ה-embeddings עבור מקטעי האודיו.</p>"
      ],
      "metadata": {
        "id": "vCR8O5tBQ0z6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = np.zeros(shape=(len(segments), 192))\n",
        "for i, segment in enumerate(segments):\n",
        "  embeddings[i] = segment_embedding(segment)\n",
        "\n",
        "embeddings = np.nan_to_num(embeddings)"
      ],
      "metadata": {
        "id": "-ZrkiasFjcDC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 id=\"-div-style-direction-rtl-dir-rtl-10-div-\"><strong><div style=\"direction:rtl\" dir=\"rtl\">14. זיהוי דוברים </div></strong></h1>\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "  <p style=\"text-align: right; direction: rtl; float: right;\">\n",
        "הריצו את התא הבא כדי לזהות את הדוברים במקטעי האודיו. תא זה משתמש באלגוריתם המכונה <a href = \"https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html\">Agglomerative Clustering</a> כדי לקבץ את ה-embeddings של מקטעי האודיו לאשכולות של מספר הדוברים שהגדרנו במשתנה <code>num_speakers</code>.</p>"
      ],
      "metadata": {
        "id": "--OdcZH1R053"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clustering = AgglomerativeClustering(num_speakers).fit(embeddings)\n",
        "labels = clustering.labels_\n",
        "for i in range(len(segments)):\n",
        "  segments[i][\"speaker\"] = 'SPEAKER ' + str(labels[i] + 1)"
      ],
      "metadata": {
        "id": "o91GmcYijgsg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 id=\"-div-style-direction-rtl-dir-rtl-10-div-\"><strong><div style=\"direction:rtl\" dir=\"rtl\">15. שמירת התמלול בקובץ טקסט </div></strong></h1>\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "  <p style=\"text-align: right; direction: rtl; float: right;\">\n",
        "הריצו את התא הבא כדי לכתוב את תוצאות זיהוי הדוברים יחד עם התמליל לקובץ טקסט. הקובץ ישמר בתיקיית <code>Whisper/Transcriptions/</code> באותו שם כמו קובץ האודיו אך עם סיומת <code>txt</code>.</p>"
      ],
      "metadata": {
        "id": "iIXH69V2UH6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def time(secs):\n",
        "  return datetime.timedelta(seconds=round(secs))\n",
        "\n",
        "# Extract the name of the audio file without the extension\n",
        "audio_filename = os.path.splitext(os.path.basename(audio_file))[0]\n",
        "\n",
        "# Construct the path to the transcription file\n",
        "transcription_file_path = os.path.join(transcription_folder_path, audio_filename + \".txt\")\n",
        "\n",
        "f = open(transcription_file_path, \"w\", encoding= 'UTF-8')\n",
        "\n",
        "for (i, segment) in enumerate(segments):\n",
        "  if i == 0 or segments[i - 1][\"speaker\"] != segment[\"speaker\"]:\n",
        "    f.write(\"\\n\" + segment[\"speaker\"] + ' ' + str(time(segment[\"start\"])) + '\\n')\n",
        "  f.write(segment[\"text\"][1:] + ' ')\n",
        "f.close()\n",
        "print(f\"\\033[1m--- Finished writing to {transcription_file_path} ---\")"
      ],
      "metadata": {
        "id": "XWrW8AG0jqtw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "https://github.com/Sourasky-DHLAB/Whisper/blob/main/Whisper_Audio.ipynb",
      "authorship_tag": "ABX9TyOcszj4CU6RoSgedQKEY/JP",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}